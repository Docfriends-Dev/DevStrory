---
layout: post
title: "temp"
description: "temp"
date: 2021-03-29
tags: []
writer: ddalam
category: server
comments: true
share: true
---


안녕하세요. 닥프렌즈 1년차🐥 서버개발자 최다영입니다. 
닥톡 서비스는 의료 전문가가 다양한 형태로 상담 컨텐츠를 제공할 수 있도록 **딥슬라이드**(TTS: Text to Speech 기술 적용), **보이스슬라이드**(STT: Speech To Text 기술 적용)외 여러 서비스를 제공하고 있습니다. ([→ 닥톡 서비스 소개 페이지에서 확인할 수 있어요!](https://www.doctalk.co.kr))

더불어 닥톡 서비스는 의료 전문가에게 편의를 주는 기능도 꾸준히 개발 중에 있는데요. 최근에는, 여러명의 목소리로 녹음된 음성을 텍스트로 변환해 채팅처럼 보여주면 의료 전문가에게 어떤 편의를 제공할 수 있을까? 라는 고민 중에 있습니다. 그래서 저희는 빠르게 이 기능을 일부 사용자에게만 테스트로 공개하는 서비스 개발해보기로 했고, 저는 프론트엔드부터 백엔드까지 전반적인 내용을 개발하게 되었습니다. 이 글에서는 어떤 구조로 오디오를 텍스트로 변환했는지, 변환된 텍스트를 어떻게 채팅 형식으로 보여주었는지에 대해 공유하려고 합니다. (녹음된 오디오를 여러 채널로 분리하는 내용은 이 글에서는 다루지 않습니다)

<br/>


### 서버 구조와 처리 순서

녹음된 오디오를 텍스트로 제공하는 서비스는 총 3개의 닥톡 서버와 네이버 CLOVA API 서버가 사용됩니다. 

![전체 로직]({{ site.url }}{{ site.baseurl }}/images/2021/temp/charting-logic.png)

**프론트 서버**는 클라이언트가 녹음 파일을 업로드하면 API를 호출해 필요한 처리들을 하며, 최종 노티를 받아 처리합니다. **미디어 서버**는 클라이언트가 업로드한 녹음 파일을 두 개의 채널로 분리하는 요청을 처리합니다. 그리고 분리된 두 개의 오디오 각각을 네이버 CLOVA API로 보내 STT 데이터를 얻습니다. 

예를 들어, 두 화자의 목소리로 녹음된 내용이 아래와 같을 때,
```
화자 A : 반갑습니다. 저는 닥톡 담당자입니다.
화자 B : 안녕하세요. 닥톡 서비스는 언제 사용하면 좋은 서비스인가요?
화자 A : 닥톡은 환자와 의사를 이어주는 주치의 메신저 플랫폼 서비스입니다. 언제든 실시간으로 병원 예약 접수를 할 수 있고, 대기자 현황까지 확인이 가능합니다. 또한 자신의 목소리 모델을 화자 이용하여 건강상담 동영상을 만들어 네이버 지식iN과 유튜브에 자동 검색노출시키는 동영상 제작, 배포도 제공한답니다.
화자 B : 네. 한번 써봐야겠네요.
화자 A : 좋아요. 이용 중 문의사항은 닥톡 홈페이지 고객센터 문의 또는 서비스 운영팀의 단톡방으로 문의해 주세요.
```

미디어 서버에서는 음성의 데시벨에 따른 계산, 잡음처리 등을 거쳐 녹음 파일과 **동일한 재생시간**을 갖는 두 개의 오디오 파일(한 파일에는 한 화자의 음성만 표현)을 생성합니다. 분리된 파일의 내용은 아래와 같습니다.
```
화자 A : 반갑습니다. 저는 닥톡 담당자입니다.
화자 A : 닥톡은 환자와 의사를 이어주는 주치의 메신저 플랫폼 서비스입니다. 언제든 실시간으로 병원 예약 접수를 할 수 있고, 대기자 현황까지 확인이 가능합니다. 또한 자신의 목소리 모델을 이용하여 건강상담 동영상을 만들어 네이버 지식iN과 유튜브에 자동 검색노출시키는 동영상 제작, 배포도 제공한답니다.
화자 A : 좋아요. 이용 중 문의사항은 닥톡 홈페이지 고객센터 문의 또는 서비스 운영팀의 단톡방으로 문의해 주세요.
```
```
화자 B : 안녕하세요. 닥톡 서비스는 언제 사용하면 좋은 서비스인가요?
화자 B : 네. 한번 써봐야겠네요.
```

이렇게 나눠진 두 파일을 각각 네이버 CLOVA API로 보내면, 각 음성이 문장 or 단어 단위로 나눠진 STT 결과(`{오디오 시작 시간, 오디오 종료 시간, 텍스트, ...}`와 같이 구성된)를 받게됩니다. 저희는 하나의 `{오디오 시작 시간, 오디오 종료 시간, 텍스트, ...}` 묶음 단위를 `segment`라고 칭하고 있는데요. 프론트엔드에서는 두 오디오에 대한 `segment` 리스트로 마치 두 화자가 텍스트로 채팅을 한 듯 표현을 합니다.

<br/>

### 프론트엔드

아래 이미지는 녹음 파일을 업로드한 클라이언트에게 제공되는 상세 페이지입니다.

![메뉴 상세 페이지]({{ site.url }}{{ site.baseurl }}/images/2021/temp/charting-menu.png)

**상세 페이지에서 제공되는 기능**
1. 화자별 텍스트 출력
2. 화자 변경
3. 텍스트 수정
4. 선택한 텍스트 영역에 해당하는 오디오 재생
5. 선택한 오디오 영역에 해당하는 텍스트 영역 포커싱

<br/>


**화자별 텍스트 출력**

서버에서 상세 페이지에 필요한 데이터를 생성할 때 고민되었던 부분은 "어떻게 하면 프론트에서 편하게 화자별 텍스트를 출력할 수 있을까" 였는데요.

두 오디오에 대한 STT API 결과는 데이터베이스에 각 오디오별로 나뉘어 저장됩니다.

![ERD]({{ site.url }}{{ site.baseurl }}/images/2021/temp/charting-erd.png)

하나의 오디오 파일(RECORDING_FILE 테이블)에 대해 하나의 STT API 요청이 있고(STT 테이블), STT API 결과로 오디오를 텍스트로 변경한 데이터가 저장되는 구조입니다(STT_SEGMENTS 테이블).

STT API 결과를 조회하는 기존 API의 메서드를 재사용했고, 그 구조는 아래와 같습니다. 각 텍스트를 표현하고, 오디오와 텍스트를 연결하기에는 편한 구조이지만, 시간 순서대로 화자의 텍스트를 보여주기에는 적합하지 않은 구조라고 생각했습니다.

```json
{
    ...

    "speaker_1_segment": {
        ...

        "seq": 8511,
        "originSegments": [
            {
                "start": 39260,
                "end": 41060,
                "text": "반갑습니다. 저는 닥톡 음성차팅 담당자입니다.",
                "confidence": 0.125,
                "segmentSeq": 51643
            },
            {
                "start": 42200,
                "end": 47640,
                "text": "모든 대화를 기록하기란 쉽지 않은데요.",
                "confidence": 0.6842105263157895,
                "segmentSeq": 51644
            },
            ...
        ],

        ...
    },
    "speaker_2_segment": {
        ...

        "seq": 8512,
        "originSegments": [
            {
                "start": 41100,
                "end": 45020,
                "text": "언제 사용하면 좋은 서비스인가요",
                "confidence": 0.129,
                "segmentSeq": 51651
            },
            {
                "start": 63200,
                "end": 78640,
                "text": "작성된 파일은 어떻게 볼 수 있나요?",
                "confidence": 0.7842105263157895,
                "segmentSeq": 51652
            },
            ...
        ],

        ...
    }

    ...
}
```

그래서 두 화자의 모든 텍스트 세그먼트를 합쳐 시작 시간 순으로 정렬한 `combinedSttSegment`을 response에 추가하기로 했습니다. `combinedSttSegment`의 `key`는 각 화자의 STT 결과 키 값인 `seq`이고, `value`는 텍스트 세그먼트의 `segmentSeq` 값 입니다.

```json
{
    ...

    "combinedSttSegment": [
        {
          "sttSeq": 8511,
          "segmentSeq": 51643
        },
        {
          "sttSeq": 8512,
          "segmentSeq": 51651
        },
        {
          "sttSeq": 8511,
          "segmentSeq": 51644
        },
        {
          "sttSeq": 8511,
          "segmentSeq": 51645
        },
        {
          "sttSeq": 8512,
          "segmentSeq": 51652
        }
    ],

    ...
}
```


 때문에 한 줄의 문장을 출력하기 위해 speaker_n_segment 오브젝트 → originSegments → start에 매번 접근해 모든 세그먼트의 시작 시간을 비교, 출력하는건 매우 비효율적이겠죠. 이처럼 매번 비교하는 일을 피하려면 두 화자의 텍스트가 시간순으로 정렬된 데이터가 필요할거라 생각했습니다.

프론트엔드에서는 `combinedSttSegment`를 순차적으로 확인하면서 두 화자를 구분해 출력합니다.
```javascript
for (let i = 0; i < combinedSttSegment.length; i++) {
    if (combinedSttSegment[i].sttSeq === speaker1SttSeq) {
        segment = speaker_1_segment[combinedSttSegment[i].segmentSeq];
        
        ...

    } else {
        segment = speaker_2_segment[combinedSttSegment[i].segmentSeq];

        ...
    }

    ...
}
```

그리고 `combinedSttSegment`를 순차적으로 확인하면서 한 화자가 연속해서 말을 했을 때는 하나의 문단으로 묶는 작업도 이뤄집니다.

![문단]({{ site.url }}{{ site.baseurl }}/images/2021/temp/charting-textArea.png)

위에 보여지는 하나의 문단은 사실 여러 세그먼트로 구성된 것입니다~

<br/>

**텍스트 수정**

STT API 결과로 받은 텍스트가 정확하지 않을 경우 클라이언트에 의해 수정될 수 있는데요. 위에서 언급했듯 하나의 문단은 여러 세그먼트로 구성될 수 있는데, 저는 각 세그먼트의 텍스트를 `<input>` 태그로 만들어 세그먼트 단위로 수정할 수 있도록 했습니다. 태그에 변경을 감지하는 이벤트를 추가했고, 특정 텍스트에서 수정이 발생했다는 것을 체크하는 방법으로는 간단히 배열을 사용했습니다.

전체 텍스트 세그먼트 길이와 크기가 같은 `isAnyChanged` 배열을 생성했습니다. `<input>` 태그에 추가한 변경 이벤트가 감지될 때마다 아래 배열에서 세그먼트 인덱스를 찾아 `true`로 변경을 합니다. 사용자가 페이지를 나갈 때 "편집없이 나가기" or "편집하고 저장하기"로 버튼을 변경해주는데 이 정보가 사용이 됩니다.

```javascript
// 배열 생성, 초기화
isAnyChanged = Array.from({length: combinedSttSegment.length}, (i) => false);
```
```javascript
// 텍스트가 수정되었을 때 버튼을 변경하는 메서드 호출
function changeSaveExitBtn() {

    let saveExitBtn = $("#save-exit-btn");

    if (isAnyChanged.includes(true)) {
        saveExitBtn.text("편집하고 저장하기");
        saveExitBtn.css("background-color", "#12ac00");
        saveExitBtn.css("color", "#FFFFFF");
    } else {
        saveExitBtn.text("편집없이 나가기");
        saveExitBtn.css("background-color", "#efefef");
        saveExitBtn.css("color", "#707070");
    }
}
```
